{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from pdf2image import convert_from_bytes\n",
    "import pytesseract\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import traceback\n",
    "from typing import Optional\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "CLAUDE_API_KEY = os.getenv(\"CLAUDE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'ocr_server_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonnet = \"anthropic/claude-3-7-sonnet-20250219\"\n",
    "haiku = \"anthropic/claude-3-5-haiku-20241022\"\n",
    "lm = dspy.LM(sonnet, api_key=CLAUDE_API_KEY)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_bytes: bytes) -> List[Dict]:\n",
    "    \"\"\"Process PDF and return structured results with bounding boxes\"\"\"\n",
    "    logger.info(\"Starting PDF processing with paragraph-based analysis and bounding boxes\")\n",
    "    \n",
    "    results = []  # Initialize results list\n",
    "    \n",
    "    try:\n",
    "        # Convert PDF to images\n",
    "        logger.debug(\"Converting PDF to images\")\n",
    "        images = convert_from_bytes(pdf_bytes)\n",
    "        logger.info(f\"Converted PDF to {len(images)} images\")\n",
    "        \n",
    "        for i, img in enumerate(images, 1):\n",
    "            logger.info(f\"Processing image {i} of {len(images)}\")\n",
    "            \n",
    "            # Get image dimensions\n",
    "            width, height = img.size\n",
    "            \n",
    "            # Convert PIL image to bytes for OCR\n",
    "            img_byte_arr = io.BytesIO()\n",
    "            img.save(img_byte_arr, format='PNG')\n",
    "            img_byte_arr = img_byte_arr.getvalue()\n",
    "            \n",
    "            # Perform OCR with bounding box information\n",
    "            logger.debug(f\"Performing OCR with bounding boxes on image {i}\")\n",
    "            \n",
    "            # Get detailed data including bounding boxes\n",
    "            ocr_data = pytesseract.image_to_data(\n",
    "                Image.open(io.BytesIO(img_byte_arr)), \n",
    "                output_type=pytesseract.Output.DICT,\n",
    "                config=r'--psm 3'\n",
    "            )\n",
    "            \n",
    "            # Process OCR data\n",
    "            n_boxes = len(ocr_data['text'])\n",
    "            for j in range(n_boxes):\n",
    "                # Skip empty text\n",
    "                if not ocr_data['text'][j].strip():\n",
    "                    continue\n",
    "                \n",
    "                # Get confidence score\n",
    "                conf = float(ocr_data['conf'][j])\n",
    "                if conf < 0:  # Skip low confidence results\n",
    "                    continue\n",
    "                \n",
    "                # Get coordinates and normalize them\n",
    "                x1 = ocr_data['left'][j] / width\n",
    "                y1 = ocr_data['top'][j] / height\n",
    "                x2 = (ocr_data['left'][j] + ocr_data['width'][j]) / width\n",
    "                y2 = (ocr_data['top'][j] + ocr_data['height'][j]) / height\n",
    "                \n",
    "                # Create result entry\n",
    "                result = {\n",
    "                    'text': ocr_data['text'][j],\n",
    "                    'bbox': {\n",
    "                        'x1': x1,\n",
    "                        'y1': y1,\n",
    "                        'x2': x2,\n",
    "                        'y2': y2,\n",
    "                        'page': i - 1  # 0-based page numbering\n",
    "                    }\n",
    "                }\n",
    "                results.append(result)\n",
    "                \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing PDF: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidelinesProcessor(dspy.Signature):\n",
    "    \"\"\"Given a guidelines text outlining rules for classifying and declassifying national security information, parse it and return a dictionary of rules stated by the document and their corresponding text. It should simply be a dict of {string: string} where the keys are all of the rules, and the values are the text of the rules. Stay as true to ground-truth document as possible, replicating the wording as much as possible.\"\"\"\n",
    "    \n",
    "    guidelines: str = dspy.InputField(desc=\"Input text containing guidelines to be processed\")\n",
    "    json_output: dict = dspy.OutputField(desc=\"JSON-formatted string representation of the guidelines, of format: {rule: text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_guidelines_to_json(guidelines_text: str, output_file: str = \"guidelines.json\") -> str:\n",
    "    \"\"\"\n",
    "    Process guidelines text and write it to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        guidelines_text (str): The guidelines text to process\n",
    "        output_file (str): Path to the output JSON file (default: \"guidelines.json\")\n",
    "        \n",
    "    Returns:\n",
    "        str: The JSON-formatted string that was written to the file\n",
    "    \"\"\"\n",
    "    # Create an instance of the processor\n",
    "    processor = dspy.ChainOfThought(GuidelinesProcessor)\n",
    "    \n",
    "    # Process the guidelines\n",
    "    result = processor(guidelines=guidelines_text)\n",
    "    \n",
    "    # Convert to JSON and write to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump({\"guidelines\": result.json_output}, f, indent=2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_path_to_bytes(pdf_path):\n",
    "    \"\"\"\n",
    "    Convert a PDF file at the specified path to bytes.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        bytes: The content of the PDF file as bytes\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            pdf_bytes = file.read()\n",
    "        return pdf_bytes\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file at {pdf_path} was not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 08:11:50,570 - __main__ - INFO - Starting PDF processing with paragraph-based analysis and bounding boxes\n",
      "2025-04-04 08:11:54,743 - __main__ - INFO - Converted PDF to 27 images\n",
      "2025-04-04 08:11:54,743 - __main__ - INFO - Processing image 1 of 27\n",
      "2025-04-04 08:11:56,080 - __main__ - INFO - Processing image 2 of 27\n",
      "2025-04-04 08:11:58,094 - __main__ - INFO - Processing image 3 of 27\n",
      "2025-04-04 08:11:59,516 - __main__ - INFO - Processing image 4 of 27\n",
      "2025-04-04 08:12:01,217 - __main__ - INFO - Processing image 5 of 27\n",
      "2025-04-04 08:12:03,120 - __main__ - INFO - Processing image 6 of 27\n",
      "2025-04-04 08:12:04,751 - __main__ - INFO - Processing image 7 of 27\n",
      "2025-04-04 08:12:06,212 - __main__ - INFO - Processing image 8 of 27\n",
      "2025-04-04 08:12:07,970 - __main__ - INFO - Processing image 9 of 27\n",
      "2025-04-04 08:12:09,549 - __main__ - INFO - Processing image 10 of 27\n",
      "2025-04-04 08:12:11,046 - __main__ - INFO - Processing image 11 of 27\n",
      "2025-04-04 08:12:12,856 - __main__ - INFO - Processing image 12 of 27\n",
      "2025-04-04 08:12:14,282 - __main__ - INFO - Processing image 13 of 27\n",
      "2025-04-04 08:12:15,761 - __main__ - INFO - Processing image 14 of 27\n",
      "2025-04-04 08:12:17,198 - __main__ - INFO - Processing image 15 of 27\n",
      "2025-04-04 08:12:18,745 - __main__ - INFO - Processing image 16 of 27\n",
      "2025-04-04 08:12:20,393 - __main__ - INFO - Processing image 17 of 27\n",
      "2025-04-04 08:12:21,887 - __main__ - INFO - Processing image 18 of 27\n",
      "2025-04-04 08:12:23,326 - __main__ - INFO - Processing image 19 of 27\n",
      "2025-04-04 08:12:25,025 - __main__ - INFO - Processing image 20 of 27\n",
      "2025-04-04 08:12:26,509 - __main__ - INFO - Processing image 21 of 27\n",
      "2025-04-04 08:12:27,986 - __main__ - INFO - Processing image 22 of 27\n",
      "2025-04-04 08:12:29,572 - __main__ - INFO - Processing image 23 of 27\n",
      "2025-04-04 08:12:31,007 - __main__ - INFO - Processing image 24 of 27\n",
      "2025-04-04 08:12:32,654 - __main__ - INFO - Processing image 25 of 27\n",
      "2025-04-04 08:12:34,029 - __main__ - INFO - Processing image 26 of 27\n",
      "2025-04-04 08:12:35,110 - __main__ - INFO - Processing image 27 of 27\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"../test_data/guideline_2.pdf\"\n",
    "\n",
    "test_pdf = pdf_path_to_bytes(pdf_path)\n",
    "\n",
    "results = process_pdf(test_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_string = \" \".join([result[\"text\"] for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m08:16:53 - LiteLLM:INFO\u001b[0m: utils.py:2975 - \n",
      "LiteLLM completion() model= claude-3-7-sonnet-20250219; provider = anthropic\n",
      "2025-04-04 08:16:53,378 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= claude-3-7-sonnet-20250219; provider = anthropic\n",
      "2025-04-04 08:17:10,755 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m08:17:10 - LiteLLM:INFO\u001b[0m: utils.py:1143 - Wrapper: Completed Call, calling success_handler\n",
      "2025-04-04 08:17:10,758 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m08:17:10 - LiteLLM:INFO\u001b[0m: cost_calculator.py:576 - selected model name for cost calculation: anthropic/claude-3-7-sonnet-20250219\n",
      "2025-04-04 08:17:10,759 - LiteLLM - INFO - selected model name for cost calculation: anthropic/claude-3-7-sonnet-20250219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning=\"I need to parse this document to extract the rules for classifying and declassifying national security information according to Executive Order 13526. I'll go through the document systematically to identify distinct rules and their corresponding text.\\n\\nThe document is organized into several sections covering:\\n1. General policy and purpose\\n2. Classification authorities and procedures\\n3. Marking requirements\\n4. Declassification procedures\\n5. Automatic declassification\\n6. Review processes\\n7. Management of classified information\\n\\nFor each rule I identify, I'll extract the exact text that describes the rule, maintaining the original wording as much as possible. I'll organize these as key-value pairs where the key is a concise description of the rule and the value is the full text of the rule from the document.\\n\\nI'll focus on extracting rules that provide specific guidance or requirements rather than general background information. I'll also ensure I capture the specific classification levels, marking requirements, and declassification procedures.\",\n",
       "    json_output={'Policy and Purpose': 'E.O. 13526 establishes a uniform system for classifying, marking, safeguarding, and declassifying national security information; i.e., information the unauthorized disclosure of which could reasonably be expected to cause damage to the national defense or foreign relations of the United States. The order is intended to keep to a minimum the amount of information that is classified and the length of time it remains classified, as well as to facilitate its eventual declassification.', 'Scope and Applicability': 'E.O. 13526 applies to the creation, use, handling, and declassification of classified information as well as access to such information. It applies to all classified information, regardless of physical format, and includes photographs, emails, tapes, web pages, and any other items created by Department personnel or contained in the files of the Department.', 'Requirements for Classification': 'Information may be originally classified under E.O. 13526 only if all the following conditions are met: (1) An original classification authority (OCA) is classifying the information; (2) The information is owned by, produced by or for, or is under the control of the U.S. Government; (3) The information falls within one or more of the categories of information listed in section 1.4 of E.O. 13526; and (4) The OCA determines that the unauthorized disclosure of the information reasonably could be expected to result in damage to the national security that can be identified or described.', 'Derivative Classification': 'Information may be classified derivatively in two ways: (1) By reproducing, extracting, or summarizing classified information or applying classification markings derived from the source material, or (2) As directed by the Classification Guide.', 'Classification Levels': 'Information may be classified at one of the three levels described below. Except as otherwise provided by statute (e.g., the Atomic Energy Act for restricted data and formerly restricted data), no other terms may be used to identify United States classified information. If there is significant doubt about the appropriate level of classification, it should be classified at the lower level. \"Top Secret\" applies to information, the unauthorized disclosure of which reasonably could be expected to cause exceptionally grave damage to the national security that the OCA is able to identify or describe. \"Secret\" applies to information, the unauthorized disclosure of which could reasonably be expected to cause serious damage to the national security that the OCA is able to identify or describe. \"Confidential\" applies to information, the unauthorized disclosure of which reasonably could be expected to cause damage to the national security that the OCA is able to identify or describe.', 'Classification Categories': 'In order to classify information, it must pertain to one of the following: (1) Military plans, weapons systems, or operations; (2) Foreign government information; (3) Intelligence activities (including covert action), intelligence sources or methods, or cryptology; (4) Foreign relations or foreign activities of the United States, including confidential sources; (5) Scientific, technological, or economic matters relating to the national security; (6) U.S. programs for safeguarding nuclear materials or facilities; (7) Vulnerabilities or capabilities of systems, installations, infrastructures, projects, plans, or protection services relating to the national security; or (8) The development, production, or use of weapons of mass destruction.', 'Foreign Government Information': 'FGI is defined in E.O. 13526 as: (1'}\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_guidelines_to_json(final_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "declass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
